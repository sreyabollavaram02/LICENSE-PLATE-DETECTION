{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95473,"status":"ok","timestamp":1712740284530,"user":{"displayName":"Kilari Harshavardhan","userId":"18407043043232351907"},"user_tz":-330},"id":"0GhhdxpPe0Dq","outputId":"e07a26c0-e6a9-4fa5-d8a8-072f23444dfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.1.45 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 28.9/107.7 GB disk)\n"]}],"source":["#for using of yolo\n","%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64633,"status":"ok","timestamp":1712740350447,"user":{"displayName":"Kilari Harshavardhan","userId":"18407043043232351907"},"user_tz":-330},"id":"vIVeh592gAcN","outputId":"91140fc4-4b0e-489d-ab11-270f5478634d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#mount your google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":866,"status":"ok","timestamp":1712692074124,"user":{"displayName":"Kilari Harshavardhan","userId":"18407043043232351907"},"user_tz":-330},"id":"gNikd35I54Ik","outputId":"109b744c-46a0-41d0-b74f-322ea6b80374"},"outputs":[{"name":"stdout","output_type":"stream","text":["/\n"]}],"source":["cd ../"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1712692078016,"user":{"displayName":"Kilari Harshavardhan","userId":"18407043043232351907"},"user_tz":-330},"id":"xLYxk67M2NCz","outputId":"e18d6ad5-8d6e-4f97-b827-07901c70c834"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;36mbin\u001b[0m@                        \u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mkaggle\u001b[0m/  \u001b[01;36mlibx32\u001b[0m@                   \u001b[01;34mopt\u001b[0m/   \u001b[01;36msbin\u001b[0m@  \u001b[01;34mtools\u001b[0m/\n","\u001b[01;34mboot\u001b[0m/                       \u001b[01;34mdev\u001b[0m/      \u001b[01;36mlib\u001b[0m@     \u001b[01;34mmedia\u001b[0m/                    \u001b[01;34mproc\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34musr\u001b[0m/\n","\u001b[01;34mcontent\u001b[0m/                    \u001b[01;34metc\u001b[0m/      \u001b[01;36mlib32\u001b[0m@   \u001b[01;34mmnt\u001b[0m/                      \u001b[01;34mroot\u001b[0m/  \u001b[01;34msys\u001b[0m/   \u001b[01;34mvar\u001b[0m/\n","cuda-keyring_1.0-1_all.deb  \u001b[01;34mhome\u001b[0m/     \u001b[01;36mlib64\u001b[0m@   NGC-DL-CONTAINER-LICENSE  \u001b[01;34mrun\u001b[0m/   \u001b[30;42mtmp\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19279,"status":"ok","timestamp":1712740396912,"user":{"displayName":"Kilari Harshavardhan","userId":"18407043043232351907"},"user_tz":-330},"id":"xwyJQIrzkQBd","outputId":"5ef95e92-2489-4ab4-ad94-30e6a6d0cbb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gradio\n","  Downloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles\u003c24.0,\u003e=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair\u003c6.0,\u003e=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.15.1 (from gradio)\n","  Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx\u003e=0.24.1 (from gradio)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub\u003e=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n","Requirement already satisfied: importlib-resources\u003c7.0,\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n","Requirement already satisfied: jinja2\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n","Requirement already satisfied: pandas\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n","Requirement already satisfied: pillow\u003c11.0,\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart\u003e=0.0.9 (from gradio)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pyyaml\u003c7.0,\u003e=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Collecting ruff\u003e=0.2.2 (from gradio)\n","  Downloading ruff-0.3.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer[all]\u003c1.0,\u003e=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.4)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n","Collecting uvicorn\u003e=0.14.0 (from gradio)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1-\u003egradio) (2023.6.0)\n","Collecting websockets\u003c12.0,\u003e=10.0 (from gradio-client==0.15.1-\u003egradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.4)\n","Requirement already satisfied: jsonschema\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.12.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (2024.2.2)\n","Collecting httpcore==1.* (from httpx\u003e=0.24.1-\u003egradio)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (1.3.1)\n","Collecting h11\u003c0.15,\u003e=0.13 (from httpcore==1.*-\u003ehttpx\u003e=0.24.1-\u003egradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.3-\u003egradio) (3.13.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.3-\u003egradio) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.3-\u003egradio) (4.66.2)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (4.50.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (1.4.5)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2023.4)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2024.1)\n","Requirement already satisfied: annotated-types\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=2.0-\u003egradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=2.0-\u003egradio) (2.16.3)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio) (8.1.7)\n","Collecting colorama\u003c0.5.0,\u003e=0.4.3 (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham\u003c2.0.0,\u003e=1.3.0 (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich\u003c14.0.0,\u003e=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio) (13.7.1)\n","Collecting starlette\u003c0.38.0,\u003e=0.37.2 (from fastapi-\u003egradio)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs\u003e=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (2023.12.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.34.0)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.18.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib~=3.0-\u003egradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio-\u003ehttpx\u003e=0.24.1-\u003egradio) (1.2.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.19.3-\u003egradio) (3.3.2)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.19.3-\u003egradio) (2.0.7)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=430e872f4180ed4e1820d0cf1482b30ed59439af678442aca4b20f08dc585cb3\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n","Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.1 ffmpy-0.3.2 gradio-4.26.0 gradio-client-0.15.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.5 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"]}],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qes5wDnYohpp"},"outputs":[],"source":["image = '/content/input_image.jpg'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVIdpnm66uSC"},"outputs":[],"source":["import os\n","import re\n","import cv2\n","import subprocess\n","from PIL import Image\n","from ultralytics import YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"V0ITbvygwtac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://ece036a779e9fda069.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://ece036a779e9fda069.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Output folder: runs/detect/predict\n","\n","image 1/1 /content/runs/detect/predict/cropped_parking_lot_283.JPG: 128x224 1 number plate, 47.4ms\n","Speed: 1.1ms preprocess, 47.4ms inference, 1616.4ms postprocess per image at shape (1, 3, 128, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : YAC3B06\n","Output folder: runs/detect/predict2\n","\n","image 1/1 /content/runs/detect/predict2/cropped_parking_lot_248.JPG: 128x224 1 number plate, 40.6ms\n","Speed: 1.0ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 128, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : BZY8Z87\n","Output folder: runs/detect/predict3\n","\n","image 1/1 /content/runs/detect/predict3/monitoring_system_63.JPG: 192x224 1 number plate, 62.5ms\n","Speed: 1.8ms preprocess, 62.5ms inference, 2.8ms postprocess per image at shape (1, 3, 192, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : AIRIA48\n","Output folder: runs/detect/predict4\n","\n","image 1/1 /content/runs/detect/predict4/monitoring_system_41.JPG: 192x224 1 number plate, 35.3ms\n","Speed: 1.0ms preprocess, 35.3ms inference, 0.8ms postprocess per image at shape (1, 3, 192, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : QBS6V\n","Output folder: runs/detect/predict5\n","\n","image 1/1 /content/runs/detect/predict5/monitoring_system_134.JPG: 192x224 2 number plates, 107.9ms\n","Speed: 1.2ms preprocess, 107.9ms inference, 1.0ms postprocess per image at shape (1, 3, 192, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : 00R1X90\n","Output folder: runs/detect/predict6\n","\n","image 1/1 /content/runs/detect/predict6/random.jpeg: 160x224 (no detections), 51.0ms\n","Speed: 1.1ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 160, 224)\n","All results stored in results/all_results.txt\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 527, in process_events\n","    response = await route_utils.call_process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 261, in call_process_api\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1786, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1338, in call_function\n","    prediction = await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 759, in wrapper\n","    response = f(*args, **kwargs)\n","  File \"\u003cipython-input-6-5318f8b1fbef\u003e\", line 197, in predict\n","    char=segment_characters(cropped_array)\n","  File \"\u003cipython-input-6-5318f8b1fbef\u003e\", line 167, in segment_characters\n","    img_lp = cv2.resize(image, (333, 75))\n","NameError: free variable 'cv2' referenced before assignment in enclosing scope\n"]},{"name":"stdout","output_type":"stream","text":["Output folder: runs/detect/predict7\n","\n","image 1/1 /content/runs/detect/predict7/parking_lot1_4.JPG: 128x224 1 number plate, 24.1ms\n","Speed: 0.8ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 128, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : RZZ8A53\n","Output folder: runs/detect/predict8\n","\n","image 1/1 /content/runs/detect/predict8/test3.jpg: 224x224 2 number plates, 69.0ms\n","Speed: 2.3ms preprocess, 69.0ms inference, 3.9ms postprocess per image at shape (1, 3, 224, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : KL01KLKL01\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 527, in process_events\n","    response = await route_utils.call_process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 261, in call_process_api\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1786, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1338, in call_function\n","    prediction = await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 759, in wrapper\n","    response = f(*args, **kwargs)\n","  File \"\u003cipython-input-6-5318f8b1fbef\u003e\", line 6, in predict\n","    yolo_command = \"yolo task=detect mode=predict model=/content/drive/MyDrive/License\\ plate\\ detection\\ project/runs/detect/25epoch_results/weights/best.pt conf=0.25 source='\" + input_path + \"' hide_labels=True line_thickness=1 \"\n","TypeError: can only concatenate str (not \"NoneType\") to str\n"]},{"name":"stdout","output_type":"stream","text":["Output folder: runs/detect/predict9\n","\n","image 1/1 /content/runs/detect/predict9/test-1.JPG: 128x224 1 number plate, 28.6ms\n","Speed: 0.7ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 128, 224)\n","All results stored in results/all_results.txt\n","\n","final predicted numer plate : BZY8Z87\n"]}],"source":["import gradio as gr\n","\n","def predict(image):\n","        input_path = image # Assuming image is a file-like object\n","        # Execute the YOLO command to perform object detection and get the output folder path\n","        yolo_command = \"yolo task=detect mode=predict model=/content/drive/MyDrive/License\\ plate\\ detection\\ project/runs/detect/25epoch_results/weights/best.pt conf=0.25 source='\" + input_path + \"' hide_labels=True line_thickness=1 \"\n","        output = subprocess.check_output(yolo_command, shell=True).decode(\"utf-8\")\n","        output_lines = output.strip().split('\\n')\n","        output_folder = None\n","        for line in output_lines:\n","            if line.startswith(\"Results saved to \"):\n","                output_folder = re.sub(r'\\x1b\\[[0-9;]*m', '', line[len(\"Results saved to \"):].strip())  # Remove ANSI escape codes\n","                break\n","        if output_folder is None:\n","            raise ValueError(\"Output folder path not found in the command output.\")\n","\n","        print(\"Output folder:\", output_folder)  # Print the output folder path for debugging\n","\n","        # Find the image file within the output folder\n","        image_files = [f for f in os.listdir(output_folder) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.JPG') or f.endswith('.jpeg')]\n","        if not image_files:\n","            raise FileNotFoundError(\"No image files found in the output folder.\")\n","\n","        # Assuming there's only one image file in the folder, select the first one\n","        image_file_path = os.path.join(output_folder, image_files[0])\n","\n","        # Open the image\n","        #img = Image.open(image_file_path)\n","\n","        # Get width and height\n","        #width = img.width\n","        #height = img.height\n","\n","        # Load the YOLOv8 model\n","        model = YOLO('/content/drive/MyDrive/License plate detection project/runs/detect/25epoch_results/weights/best.pt')\n","\n","        # Perform inference on the image\n","        results = model(image_file_path)\n","\n","        # Extract bounding boxes, classes, names, and confidences\n","        boxes = results[0].boxes.xyxy.tolist()\n","        classes = results[0].boxes.cls.tolist()\n","        names = results[0].names\n","        confidences = results[0].boxes.conf.tolist()\n","\n","        # Create a folder to store the results\n","        output_folder = \"results\"\n","        os.makedirs(output_folder, exist_ok=True)\n","\n","        # Create a text file to store all the results\n","        output_file = os.path.join(output_folder, \"all_results.txt\")\n","        with open(output_file, \"w\") as f:\n","            # Iterate through the results\n","            x=[]\n","            for i, (box, cls, conf) in enumerate(zip(boxes, classes, confidences)):\n","                x.append(box)\n","                #x1, y1, x2, y2 = box\n","                confidence = conf\n","                detected_class = cls\n","                name = names[int(cls)]\n","\n","                # Write the result to the file\n","                f.write(f\"BBox: {x[i][0]},{x[i][1]},{x[i][2]},{x[i][3]}\\n\")\n","\n","        print(f\"All results stored in {output_file}\")\n","\n","        import numpy as np\n","        from PIL import Image\n","        import matplotlib.pyplot as plt\n","\n","        # Load the image as a NumPy array\n","        image_array = np.array(Image.open(image_file_path))\n","\n","        for i in range(len(x)):\n","\n","            x1, x2 = min(x[i][0], x[i][2]), max(x[i][0], x[i][2])\n","            y1, y2 = min(x[i][1], x[i][3]), max(x[i][1], x[i][3])\n","\n","            # Crop the image array using the floating-point coordinates\n","            cropped_array = image_array[int(y1):int(y2), int(x1):int(x2)]\n","\n","            # Convert the cropped array back to an image\n","            cropped_image = Image.fromarray(cropped_array)\n","\n","            # Save the cropped image with a unique filename incorporating the index i\n","            cropped_image.save(f\"cropped_image_{i}.jpg\")\n","            np.save(f\"cropped_array_{i}.npy\", cropped_array)\n","\n","            # Display the cropped image\n","            plt.imshow(cropped_image)\n","            plt.show()\n","\n","            import cv2\n","        # Match contours to license plate or character template\n","        def find_contours(dimensions, img) :\n","            plt.imshow(img)\n","            plt.show()\n","            # Find all contours in the image\n","\n","            cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","            # Retrieve potential dimensions\n","            lower_width = dimensions[0]\n","            upper_width = dimensions[1]\n","            lower_height = dimensions[2]\n","            upper_height = dimensions[3]\n","\n","            # Check largest 5 or  15 contours for license plate or character respectively\n","            cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n","\n","            ii = cv2.imread('contour.jpg')\n","            # Set the border pixels to white\n","            border_size = 5\n","            ii[:border_size+5, :] = 255  # Top border\n","            ii[-border_size:, :] = 255  # Bottom border\n","            ii[:, :border_size] = 255  # Left border\n","            ii[:, -border_size:] = 255  # Right border\n","            plt.imshow(ii)\n","            plt.show()\n","            x_cntr_list = []\n","            target_contours = []\n","            img_res = []\n","            for cntr in cntrs :\n","                # detects contour in binary image and returns the coordinates of rectangle enclosing it\n","                intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n","\n","                # checking the dimensions of the contour to filter out the characters by contour's size\n","                if intWidth \u003e lower_width and intWidth \u003c upper_width and intHeight \u003e lower_height and intHeight \u003c upper_height :\n","                    x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n","\n","                    char_copy = np.zeros((44,24))\n","                    # extracting each character using the enclosing rectangle's coordinates.\n","                    char = img[intY:intY+intHeight, intX:intX+intWidth]\n","                    char = cv2.resize(char, (20, 40))\n","\n","                    cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n","                    plt.imshow(ii, cmap='gray')\n","                    plt.title('Predict Segments')\n","\n","                    # Make result formatted for classification: invert colors\n","                    char = cv2.subtract(255, char)\n","\n","                    # Resize the image to 24x44 with black border\n","                    char_copy[2:42, 2:22] = char\n","                    char_copy[0:2, :] = 0\n","                    char_copy[:, 0:2] = 0\n","                    char_copy[42:44, :] = 0\n","                    char_copy[:, 22:24] = 0\n","\n","                    img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n","\n","            # Return characters on ascending order with respect to the x-coordinate (most-left character first)\n","\n","            plt.show()\n","            # arbitrary function that stores sorted list of character indeces\n","            indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n","            img_res_copy = []\n","            for idx in indices:\n","                img_res_copy.append(img_res[idx])# stores character images according to their index\n","            img_res = np.array(img_res_copy)\n","\n","            return img_res\n","        # Find characters in the resulting images\n","        def segment_characters(image) :\n","\n","            # Preprocess cropped license plate image\n","            img_lp = cv2.resize(image, (333, 75))\n","            img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n","            _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","            img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n","            img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n","\n","            LP_WIDTH = img_binary_lp.shape[0]\n","            LP_HEIGHT = img_binary_lp.shape[1]\n","\n","            # Make borders white\n","            img_binary_lp[0:3,:] = 255\n","            img_binary_lp[:,0:3] = 255\n","            img_binary_lp[72:75,:] = 255\n","            img_binary_lp[:,330:333] = 255\n","\n","            # Estimations of character contours sizes of cropped license plates\n","            dimensions = [LP_WIDTH/6,\n","                              LP_WIDTH/2,\n","                              LP_HEIGHT/10,\n","                              2*LP_HEIGHT/3]\n","            plt.imshow(img_binary_lp, cmap='gray')\n","            plt.title('Contour')\n","            plt.show()\n","            cv2.imwrite('contour.jpg',img_binary_lp)\n","\n","            # Get contours within cropped license plate\n","            char_list = find_contours(dimensions, img_binary_lp)\n","\n","            return char_list\n","        cropped_array = np.load(\"cropped_array_0.npy\")\n","        char=segment_characters(cropped_array)\n","        from math import sqrt\n","        from sklearn.preprocessing import MinMaxScaler\n","\n","        def ReLU(X):\n","            \"\"\"ReLU function\"\"\"\n","            return np.maximum(0,X)\n","\n","        def softmax(X):\n","            \"\"\"Softmax function\"\"\"\n","            e_X = np.exp(X - np.max(X))\n","            return e_X / e_X.sum(axis=0)\n","\n","        def deriv_ReLU(X):\n","            \"\"\"Derivative of ReLU function\"\"\"\n","            return X \u003e 0\n","\n","        def one_hot_encoder(y):\n","            \"\"\"One Hot Encoder\"\"\"\n","            oh_y = np.zeros((y.size, y.max() + 1))\n","            oh_y[np.arange(y.size), y] = 1\n","            return oh_y.T\n","\n","        def get_predictions(A2):\n","            return np.argmax(A2, axis=0)\n","\n","        def get_accuracy(pred, y):\n","            #print(pred, y)\n","            return np.sum(pred == y) / y.size\n","\n","        def model_pred(W1, b1, W2, b2, X):\n","            \"\"\"Forward propagation steps\"\"\"\n","            Z1 = W1.dot(X) + b1\n","            A1 = ReLU(Z1)\n","            Z2 = W2.dot(A1) + b2\n","            A2 = softmax(Z2)\n","            pred = get_predictions(A2)\n","            return pred\n","        # Load weights and biases from files\n","        W1 = np.load('/content/drive/MyDrive/License plate detection project/weights_cnn/w1.npy')\n","        W2 = np.load('/content/drive/MyDrive/License plate detection project/weights_cnn/w2.npy')\n","        b1 = np.load('/content/drive/MyDrive/License plate detection project/weights_cnn/bias1.npy')\n","        b2 = np.load('/content/drive/MyDrive/License plate detection project/weights_cnn/bias2.npy')\n","\n","\n","        #W1 = np.load('/content/drive/MyDrive/License plate detection project/letter dataset/w1.npy')\n","        #W2 = np.load('/content/drive/MyDrive/License plate detection project/letter dataset/w2.npy')\n","        #b1 = np.load('/content/drive/MyDrive/License plate detection project/letter dataset/b1.npy')\n","        #b2 = np.load('/content/drive/MyDrive/License plate detection project/letter dataset/b2.npy')\n","\n","          # Define the width and height for resizing\n","        target_shape = (28, 28)\n","        # Loop through the images in 'char'\n","        output=''\n","        for i, image_data in enumerate(char):\n","            # Resize the image using cv2.resize()\n","            img_resized = cv2.resize(image_data, target_shape)  # Resize image\n","\n","            # Flatten image into 1D array\n","            img_flattened = img_resized.flatten()  # Flatten image into 1D array\n","\n","            img_flattened = img_flattened.reshape(-1, 1)\n","\n","            # Perform predictions using the model\n","            test_pred = model_pred(W1, b1, W2, b2, img_flattened)\n","            #print(type(test_pred))\n","            my_char=None\n","            if(test_pred[0]\u003e9):\n","              my_char = chr(ord('A') + test_pred[0] - 10)\n","            else:\n","              my_char=str(test_pred[0])\n","            output+=my_char\n","\n","\n","            # Display the resized image using cv2.imshow()\n","            #plt.imshow(img_resized, cmap='gray')  # Display the image\n","            #plt.axis('off')  # Turn off axis labels\n","            #plt.show()\n","            # Print predictions and length of flattened image\n","            #print(my_char )\n","\n","        print(\"\\nfinal predicted numer plate :\",output)\n","        return output\n","\n","#out=predict(image)\n","#print(\"hiiii\",out)\n","iface = gr.Interface(fn=predict, inputs=\"file\", outputs=\"text\", title=\"License Plate Detection\", description=\"Upload an image containing a license plate to detect the characters on the plate.\")\n","iface.launch(debug=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCvnpu9bbmrt"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOWUDuqs8fOxdRzQPJ75tNW","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}